<!DOCTYPE HTML>
<!--
	Story by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Yu (Emma) Wang, Performance for Large Models.</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
    <style type="text/css">
      .fa-download, .fa-github { padding-right: 0.3em }
    </style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="divided">

				<!-- One -->
					<section class="banner style1 orient-left content-align-left image-position-center fullscreen onload-image-fade-in onload-content-fade-right">
						<div class="content">
							<h1>Yu (Emma) Wang</h1>
              <p class="major"> I am a Staff Software Engineer at Google DeepMind. I specialized in serving
system design and optimization for large models. I lead the Multimodal Serving team that optimized
Veo serving performance by 5x. I led my previous team that optimized Gemini serving performance by up to 2.5x.
                I obtained my Ph.D from Harvard University with
                the <a href="http://vlsiarch.eecs.harvard.edu/">Harvard Architecture, Circuits, and Compiler
                Group</a> in 2019. My advisors are
                Prof. <a href="http://www.eecs.harvard.edu/~dbrooks/">David Brooks</a>
                and Prof. <a href="http://www.seas.harvard.edu/directory/guyeon">Gu-Yeon Wei</a>.
                I received my Bachelor of Science degree in Computer Science from Shanghai Jiao Tong University in 2013.
          </p>
						</div>
						<div class="image">
							<img src="images/rsz_banner.jpg" alt="" />
						</div>
					</section>

				<!-- Spotlight -->
					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in" id="first">
						<div class="content">
          <p> Email: (@ yuemmawang (. google com)) </p>
          <p> <a href='https://scholar.google.com/citations?user=cIt4my0AAAAJ&hl=en' class='button default'> Google Scholar Profile </a> </p>
          <p> (Emma reserves the copyright of all the photos on this website.) </p>
						</div>
						<div class="image">
							<img src="images/emma.jpg" alt="" />
						</div>
					</section>

				<!-- Four -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Professional Experience</h2>
							<div class="index align-left">
								<!-- Unordered List -->
									<section>
										<header>
											<h4>Staff Software Engineer, Google DeepMind</h4>
                      <h4>April 2023 -- Present</h4>
										</header>
										<div class="content">
											<ul>
                        <li>Leading the Multimodal Serving team in Google DeepMind.</li>
                         <ul>
                          <li>Designed and implementing a serving system to cater different multimodal
model serving needs.</li>
<li>Optimized three generations of Veo for serving, achieved up to <b>30% speedup
for Veo 1</b>, over <b>5x for Veo 2 and Veo 3</b>.</li>
                         </ul>
                        <li>Optimized serving performance of Gemini-based products.</li>
                         <ul>
                          <li><b>3.4x speedup for Project Astra</b>, which was <a
href=https://www.youtube.com/watch?v=nXVvvRhiGjI>launched in Google I/O 2024</a>.</li>
                          <li>Up to <b>2.6x speedup for Search</b>, and 1.6x for a long context model for a Cloud product.</li>
                          <li><b>Google Tech Impact Award 2024</b></li>
                          <li><b>Google Editor's Choice Perfy Award 2024</b></li>
                          <li><b>Google Gold Perfy Award 2024 x 2</b></li>
                          <li>Google Silver Perfy Award 2024</li>
                         </ul>
											</ul>
										</div>
									</section>

									<section>
										<header>
											<h4>Senior Software Engineer, Google</h4>
                      <h4>April 2021 -- April 2023</h4>
										</header>
										<div class="content">
											<ul>
                        <li>Optimized serving performance of Google's large language model products, led a virtual
team of over 10 engineers.</i>
                        <ul>
                        <li>Achieved up to <b>2.5x speedup for Bard</b> (later renamed as Gemini),
<b>1.7x for Search</b>, <b>1.3x for Cloud</b>.</li>
                        <li>Applied optimizations across the stacks including compilers (e.g., fusion, lowering, scheduling), models (such as sharding
optimization, rewriting computations to be more TPU-friendly), and compiler flag autotuning.</li>
                        <li>Proposed a systematic and general performance analysis methodology,
widely used for onboarding new performance engineers.</li>
                        <li><b>Google Cloud Tech Impact Award 2023</b></li>
                        <li><b>Google Editor's Choice Perfy Award 2023</b></li>
                        <li>Three of Google Silver Perfy Award 2023</li>
                        </ul>
                        <li>Productionized the automatic model partitioning algorithm in Alpa
(co-authored <a href=https://research.google/blog/alpa-automated-model-parallel-deep-learning/>blog
post</a>), implemented optimizations to scale Google wide. Led the team to <a href=https://github.com/pytorch/xla/issues/6322>open source it in
PyTorch XLA</a>.</li>
                        <li>Conducted model partitioning autotuning, speeded up serving of an
earlier version of Bard by 10%.
                        <li>Designed <a
href='https://patents.google.com/patent/WO2023234952A1/en?oq=WO2023234952A1'>the 2nd generation of
the automatic system</a> to deploy <a href='https://mangpo.net/papers/xla-autotuning-pact2021.pdf'>
multi-pass Machine Learning compiler autotuning</a> for fleetwide Google ML workloads, saved
significant fleetwide TPU resources. </li>
                      <ul>
                       <li>After founding the project and the team, I handed off to a new TLM and moved on to
other projects. This new system recently finished landing most optimizations to Google fleet and
awarded <b>Google Gold Perfy Award 2025</b>.</li>
                      </ul>
											</ul>
										</div>
									</section>

									<section>
										<header>
											<h4>Software Engineer, Google</h4>
                      <h4>Nov 2019 -- April 2021</h4>
										</header>
										<div class="content">
											<ul>
                        <li> Designed and implemented <a
href='https://patents.google.com/patent/US20240118875A1/en?oq=US20240118875A1'>an automatic system
(US Patent)</a> to deploy <a href='https://mangpo.net/papers/xla-autotuning-pact2021.pdf'> multi-pass
                             Machine Learning compiler autotuning</a> that optimizes fleetwide Google ML
                             workloads.</li>
                          <ul>
                          <li> It saves significant fleetwide TPU resources.</li>
                          <li> <b>Google Editor's Choice Perfy Award 2021.</b></li>
                          <li> Google ML Product Excellence Award 2021. </li>
                          <li> Special Efficiency Award 2021. </li>
                          </ul>
                          <li> Optimized MLPerf BERT training on 4k TPU v3 pod, set the world record
of 23 seconds for BERT training (<a
href=https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer>blog
post</a>). Authored <a
href=https://proceedings.mlsys.org/paper_files/paper/2021/file/c0d16b623be8b439d9c075eb5a97efd1-Paper.pdf>the
MLSys'21 paper</a> to summarize the optimizations and lessons.
                        <ul>
                        <li> Google Silver Perfy Award 2020 and 2021.
                        </ul>
                          <li> Designed and implemented <a
href=https://patents.google.com/patent/US20240118920A1/en?oq=US20240118920A1>a workload scheduling
queue in TPU runtime (US Patent)</a>.</li>
											</ul>
										</div>
									</section>

									<section>
										<header>
											<h4>Research Assistant, Harvard University</h4>
                      <h4>Sep 2013 -- Sep 2019</h4>
										</header>
										<div class="content">
											<ul>
												<li>Conducted deep and systematic performance analysis for machine learning workloads and extracted architectural insights to optimize those workloads.</li>
                        <li>See <a
href=https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cIt4my0AAAAJ&cstart=20&pagesize=80&citation_for_view=cIt4my0AAAAJ:lSLTfruPkqcC>my
dissertation</a>.</li>
											</ul>
										</div>
									</section>

									<section>
										<header>
										  <h4>Research Intern, Facebook</h4>
                      <h4>Mentors: Xiaodong Wang and Carole-Jean Wu</h4>
										  <h4>Nov 2018 -- Feb 2019</h4>
										</header>
										<div class="content">
											<ul>
                        <li>Performed performance comparison across different deep learning
                            frameworks and identified the source of performance difference in depth.</li>
                        <li>Extracted insights to optimize Caffe2 from the analysis results.</li>
											</ul>
										</div>
									</section>

									<section>
										<header>
										  <h4>Software Engineering Intern, Google Platforms</h4>
                      <h4>Mentor: Hui Huang</h4>
                      <h4>May -- Aug 2018</h4>
										</header>
										<div class="content">
											<ul>
                        <li>Benchmarked 3rd generation of Tensor Processing Units (TPU v3) with
                            state-of-the-art deep learning workloads.</li>
                        <li>Predicted potential bottlenecks of Cloud TPU v3.</li>
                        <li>Quantified the impact of NUMA-aware allocation for Cloud TPU v3.</li>
                        <li>Silver Perfy Award in 2019 Q1 at Google.</li>
											</ul>
										</div>
									</section>

									<section>
										<header>
										  <h4>Software Engineering Intern, Google Brain</h4>
                      <h4>Mentor: Cliff Young</h4>
                      <h4>Sep -- Dec 2017</h4>
										</header>
										<div class="content">
											<ul>
                        <li>Benchmarked 2nd generation of Tensor Processing Units (TPU v2) with state-of-the-art
                            deep learning workloads and analyzed their bottlenecks.</li>
                        <li>Quantified performance scalability and speedup of Cloud TPU v2.</li>
											</ul>
										</div>
									</section>

									<section>
										<header>
										  <h4>Parallel Computing Intern, Intel Labs</h4>
                      <h4>Mentor: Victor Lee</h4>
                      <h4>July 2015 -- Jan 2016</h4>
										</header>
										<div class="content">
											<ul>
                        <li>Developed a set of tools to characterize CPU workloads, extracted platform independent
                            features including memory locality, memory footprint, and branch entropy.</li>
											</ul>
										</div>
									</section>

									<section>
										<header>
										  <h4>Research Assistant, Shanghai Jiao Tong University</h4>
                      <h4>Mentor: Prof. Bo Yuan</h4>
                      <h4>Sep 2011 -- July 2013</h4>
										</header>
										<div class="content">
											<ul>
                        <li>Optimized a Bayesian network learning algorithm and implemented on GPU.</li>
                        <li>Achieved a 143× speedup on GPU over CPU.</li>
                        <li>Applied this method to networks of up to 125 nodes.</li>
											</ul>
										</div>
									</section>

									<section>
										<header>
										  <h4>Research Assistant, Shanghai Jiao Tong University</h4>
                      <h4>Mentor: Prof. Xiaoyao Liang</h4>
                      <h4>June 2012 -- July 2013</h4>
                      <h4></h4>
										</header>
										<div class="content">
											<ul>
                        <li>Designed a hardware profile-guided scheduler for green datacenters.</li>
                        <li>Reduce the datacenter energy cost up to 54% while maintaining fairly
                          balanced processor utilization.</li>
											</ul>
										</div>
									</section>

              </div>
              </div>
				</section>
				<!-- Three -->
					<section class="wrapper style1 align-left">
						<div class="inner">
							<h2>Publications</h2>
								<p> 
                <a href="https://arxiv.org/pdf/2507.06261" class="icon style1 fa-download"></a>
Gemini Team. <I>"Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality,
Long Context, and Next Generation Agentic Capabilities."</I> arXiv preprint arXiv:2507.06261 (2025).
                </p>

								<p> 
                <a href="https://arxiv.org/abs/2408.00118" class="icon style1 fa-download"></a>
Gemma Team. <I>"Gemma 2: Improving open language models at a practical size."</I> arXiv preprint arXiv:2408.00118 (2024).
                </p>

								<p> 
                <a href="https://arxiv.org/abs/2403.05530" class="icon style1 fa-download"></a>
Gemini Team. <I>"Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context."</I> arXiv preprint arXiv:2403.05530 (2024).
                </p>

								<p> 
                <a href="https://arxiv.org/abs/2408.00118" class="icon style1 fa-download"></a>
Gemma Team. <I>"Gemma 2: Improving open language models at a practical size."</I> arXiv preprint arXiv:2408.00118 (2024).
                </p>

								<p> 
                <a href="https://arxiv.org/pdf/2312.11805" class="icon style1 fa-download"></a>
Gemini Team. <I>"Gemini: A family of highly capable multimodal models, 2024."</I> arXiv preprint arXiv:2312.11805 10 (2024).
                </p>

								<p> 
                <a href="https://arxiv.org/pdf/2310.03675" class="icon style1 fa-download"></a>
Schiemer, Martin, Clemens JS Schaefer, Jayden Parker Vap, Mark James Horeni, <b>Yu Emma Wang</b>, Juan Ye,
and Siddharth Joshi. <I>"Hadamard domain training with integers for class incremental quantized
learning."</I> arXiv preprint arXiv:2310.03675 (2023).
                </p>

								<p> 
                <a href="https://arxiv.org/pdf/2306.04879" class="icon style1 fa-download"></a>
Clemens JS Schaefer, Navid Lambert-Shirzad, Xiaofan Zhang, Chiachen Chou, Tom Jablin, Jian Li,
Elfie Guo, Caitlin Stanton, Siddharth Joshi, and <b>Yu Emma Wang</b>. <I>"Augmenting hessians with inter-layer
dependencies for mixed-precision post-training quantization."</I> arXiv preprint arXiv:2306.04879 (2023).
                </p>

								<p> 
                <a href="https://arxiv.org/pdf/2302.01382" class="icon style1 fa-download"></a>
Clemens JS Schaefer, Elfie Guo, Caitlin Stanton, Xiaofan Zhang, Tom Jablin, Navid Lambert-Shirzad,
Jian Li, Chiachen Chou, Siddharth Joshi, and <b>Yu Emma Wang</b>. <I>"Mixed precision post training
quantization of neural networks with sensitivity guided search."</I> arXiv preprint arXiv:2302.01382 (2023).
                </p>

								<p> 
                <a href="https://arxiv.org/pdf/2201.08539" class="icon style1 fa-download"></a>
Zhang, Xiaofan, Zongwei Zhou, Deming Chen, and <b>Yu Emma Wang</b>. <I>"AutoDistill: An end-to-end framework
to explore and distill hardware-efficient language models."</I> arXiv preprint arXiv:2201.08539 (2022).
                </p>

								<p> 
                <a href="https://proceedings.mlr.press/v162/du22c.html" class="icon style1 fa-download"></a>
Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi
Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P Bosma, Zongwei Zhou, Tao Wang,
<b>Yu Emma Wang</b> et al. <I>"Glam: Efficient scaling of language models with mixture-of-experts."</I> In
International conference on machine learning, pp. 5547-5569. PMLR, 2022.
                </p>

                <p>
                <a href=https://mangpo.net/papers/xla-autotuning-pact2021.pdf class="icon style1 fa-download"></a>
Phitchaya Mangpo Phothilimthana, Amit Sabne, Nikhil Sarda, Karthik Srinivasa Murthy, Yanqi Zhou,
Christof Angermueller, Mike Burrows, Sudip Roy, Ketan Mandke, Rezsa Farahani, <b>Yu Emma Wang</b> et
al. <I>"A flexible approach to autotuning multi-pass machine learning compilers."</I> In 2021 30th International Conference on Parallel Architectures and Compilation Techniques (PACT), pp. 1-16. IEEE, 2021.
                </p>
								<p> 
                <a href="https://proceedings.mlsys.org/paper/2021/file/28dd2c7955ce926456240b2ff0100bde-Paper.pdf" class="icon style1 fa-download"></a>
                Sameer Kumar, <b>Yu Emma Wang</b>, Cliff Young, James Bradbury, Anselm Levskaya, Blake Hechtman,
                Dehao Chen, HyoukJoong Lee, Mehmet Deveci, Naveen Kumar, Pankaj Kanwar, Shibo Wang,
                Skye Wanderman-Milne, Steve Lacy, Tao Wang, Tayo Oguntebi, Yazhou Zu, Yuanzhong Xu,
                Andy Swing, <I>"Exploring the limits of Concurrency in ML Training on Google TPUs."</I> MLSys (2021).
                </p>

								<p> 
                <a href="http://arxiv.org/abs/1908.04705" class="icon style1 fa-download"></a>
								<a href="https://github.com/Emma926/mcbench" class="icon style1 fa-github"></a>
                <b>Yu Emma Wang</b>, Carole-Jean Wu, Xiaodong Wang, Kim Hazelwood, David Brooks, 
                    <I>"Exploiting Parallelism Opportunities with Deep Learning Frameworks."</I> 
                    arXiv preprint arXiv:1908.04705 (2019).
                </p>

                <p>
								<a href="publications/wang-mlsys2020.pdf" class="icon style1 fa-download"></a>
								<a href="http://github.com/Emma926/paradnn" class="icon style1 fa-github"></a>
                    <b>Yu Emma Wang</b>, Gu-Yeon Wei, David Brooks, <I>"A Systematic Methodology
                    for Analysis of Deep Learning Hardware and Software Platforms."</I> MLSys (2020).
                </p>

                <p class='tab'>
								<a href="http://arxiv.org/abs/1907.10701" class="icon style1 fa-download"></a>
								<a href="http://github.com/Emma926/paradnn" class="icon style1 fa-github"></a>
                    (The arXiv version of the above paper) <b>Yu Emma Wang</b>, Gu-Yeon Wei, David
                    Brooks, <I>"Benchmarking TPU, GPU and CPU for Deep Learning."</I> arXiv
                    preprint arXiv:1907.10701 (2019).
                </p>

                <p> 
								<a href="publications/wang-ispass2019.pdf" class="icon style1 fa-download"></a>
								<a href="http://github.com/Emma926/BayesSuite" class="icon style1 fa-github"></a>
                    <b>Yu Emma Wang</b>, Yuhao Zhu, Glenn G. Ko, Brandon Reagen, Gu-Yeon Wei, and
                    David Brooks. <I>"Demystifying Bayesian Inference Workloads."</I> IEEE International
                    Symposium on Performance Analysis of Systems and Software (ISPASS), pp. 177-189. IEEE, 2019.
                </p>

          <p> 
              <a href = publications/wang-taco2019.pdf class="icon style1 fa-download"></a>
								<a href="https://github.com/Emma926/cpu_selection" class="icon style1 fa-github"></a>
              <b>Yu Emma Wang</b>, Victor Lee, Gu-Yeon Wei, and David Brooks. <I>"Predicting New
              Workload or CPU Performance by Analyzing Public Datasets."</I> ACM Transactions on
              Architecture and Code Optimization (TACO). vol. 15, no. 4 (2019): 53:1–53:21.
          </p>

          <p> <a href = publications/wang-tpds2016.pdf class="icon style1 fa-download"></a>
								<a href="http://github.com/Emma926/BN-GPU" class="icon style1 fa-github"></a>
              <b>Yu Emma Wang</b>, Weikang Qian, Shuchang Zhang, Xiaoyao Liang, and Bo Yuan. <I>"A
              Learning Algorithm for Bayesian Networks and Its Efficient Implementation on GPU,"</I> IEEE Transactions
              on Parallel and Distributed Systems. vol. 27, no. 1 (2016): 17–30.
          </p>
     
          <p> 
              <a href = publications/tang-icpp2015.pdf class="icon style1 fa-download"></a>
              Weichao Tang, <b>Yu Emma Wang</b>, Haopeng Liu, Tao Zhang, Chao Li, and Xiaoyao
              Liang. </I>"Exploring Hardware Profile-Guided Green Datacenter Scheduling."</I>
              International Conference on Parallel Processing (ICPP), pp. 11-20. 2015.
          </p>
					</section>

					<section class="wrapper style1 align-left">
						<div class="inner">
							<h2>Dissertation</h2>
                <p>
              <a href = publications/wang-thesis2019.pdf class="icon style1 fa-download"></a>
							      Yu Emma Wang. "Performance Analysis for Machine Learning Applications." PhD
                    Dissertation, Harvard University, Nov 2019.
                </p>
					</section>

					<section class="wrapper style1 align-left">
						<div class="inner">
							<h2>Patents</h2>
                <p>
              <a href =https://patents.google.com/patent/US20240118875A1/en?oq=US20240118875A1  class="icon style1 fa-download"></a>
							     <b>Yu Emma Wang</b>, Dehao Chen, Phitchaya Mangpo Phothilimthana, "Deploying optimization
profiles for compiling computer programs in data centers." 2023.
                </p>
                <p>
              <a href =https://patents.google.com/patent/WO2023234952A1/en?oq=WO2023234952A1  class="icon style1 fa-download"></a>
							     Hyojun Kim, Xiao Yu, <b>Yu Emma Wang</b>, Phitchaya Mangpo Phothilimthana,
"Caching compilation outputs using optimization profiles." 2022.
                </p>
                <p>
              <a href =https://patents.google.com/patent/US20240118920A1/en?oq=US20240118920A1  class="icon style1 fa-download"></a>
							     <b>Yu Emma Wang</b>, Thomas Benjamin Jablin, Caitlin King Stanton, "Workload
scheduling using queues with different priorities." 2022.
                </p>
					</section>
				<!-- Six -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Open-Source Software</h2>
              <p> Feel free to download our software and use in your project. If you do, please cite our corresponding papers. </p>
							<div class="items style1 medium onscroll-fade-in">
								<section>
									<a href="https://github.com/Emma926/paradnn"><span class="icon style2 major fa-bar-chart"></span></a>
									<h3><a href="https://github.com/Emma926/paradnn">ParaDnn</a></h3>
                  <p> <a href="https://github.com/Emma926/paradnn">ParaDnn</a> is a tool that
enables systematic performance analysis for deep learning platforms. </p>
								</section>
								<section>
									<a href="https://github.com/Emma926/mcbench"><span class="icon style2 major fa-bolt"></span></a>
									<h3><a href="https://github.com/Emma926/mcbench">Mille Crepe Bench</a></h3>
                  <p> <a href="https://github.com/Emma926/mcbench">Mille Crepe Bench</a> is a
multi-layer performance analysis tool for deep learning frameworks. </p>
								</section>
								<section>
									<a href="https://github.com/Emma926/BayesSuite"><span class="icon style2 major fa-leaf"></span></a>
									<h3><a href="https://github.com/Emma926/BayesSuite">BayesSuite</a></h3>
                  <p> <a href="https://github.com/Emma926/BayesSuite">BayesSuite</a> is a Bayesian inference benchmark suite based on Stan. </p>
								</section>
								<section>
									<a href="https://github.com/Emma926/BN-GPU"><span class="icon style2 major fa-paper-plane"></span></a>
									<h3><a href="https://github.com/Emma926/BN-GPU">BN-GPU</a></h3>
                  <p> <a href="https://github.com/Emma926/BN-GPU">BN-GPU</a> is a GPU implementation
                      of a Bayesian network learning algorithm. </p>
								</section>
							</div>
						</div>
					</section>

				<!-- Four -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Professional Service</h2>
							<div class="index align-left">
								<!-- Unordered List -->
									<section>
										<header>
											<h3>Technical Program Committee</h3>
										</header>
										<div class="content">
											<ul>
                        <li>Machine Learning and Systems Rising Stars 2024</li>
												<li>Conference on Machine Learning and Systems (MLSys) 2024</li>
												<li>ACM International Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS) 2024</li>
												<li>ACM/IEEE Supercomputing Conference (SC) 2023</li>
												<li>MLBench workshop in MLSys'23</li>
												<li>Conference on Machine Learning and Systems (MLSys) 2023</li>
												<li>ACM/IEEE Supercomputing Conference (SC) 2022</li>
												<li>Conference on Machine Learning and Systems (MLSys) 2022</li>
												<li>MLBench workshop in MLSys'21</li>
											</ul>
									</section>

									<section>
										<header>
                      <h3>Journal reviews</h3>
										</header>
										<div class="content">
											<ul>
												<li>IEEE Computer Architecture Letters (CAL)</li>
												<li>ACM Transactions on Architecture and Code Optimization (TACO)</li>
											</ul>
										</div>
									</section>

              </div>
              </div>
				</section>

				<!-- Four -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Talks</h2>
							<div class="index align-left">
								<!-- Unordered List -->
									<section>
										<header>
											<h3>Demystify Bayesian Inference Workloads</h3>
										</header>
										<div class="content">
											<ul>
												<li>ISPASS, Madison, WI, March 2019.</li>
												<li>ADA Symposium, Ann Arbor, MI, April 2019.</li>
											</ul>
									</section>

									<section>
										<header>
                      <h3>A Systematic Methodology for Analysis of Deep Learning Platforms</h3>
										</header>
										<div class="content">
											<ul>
												<li>Google, Aug 2018.</li>
												<li>Google, Aug 2018.</li>
												<li>Google, Sep 2018. (No, the three lines are not typos.)</li>
												<li>Facebook, Sep 2018.</li>
												<li>ADA Center, Dec 2018.</li>
												<li>IBM, March 2019.</li>
												<li>Micron, May 2019.</li>
                        <li>MLSys, March 2020.</li>
											</ul>
										</div>
									</section>

              </div>
              </div>
				</section>



				<!-- Five -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Photography</h2>
                <p> I enjoy food, traveling, photographing and interacting with people.
                    These are samples of the outcome. </p> 
                <p> For more photos please refer to <a href="http://500px.com/emmawong926">my 500PX page</a>.
                    Copyright reserved :) </p>
						</div>
						<!-- Gallery -->
							<div class="gallery style2 medium lightbox onscroll-fade-in">
								<article>
									<a href="images/ORG_DSC00868.JPG" class="image">
										<img src="images/ORG_DSC00868.JPG" alt="" />
									</a>
									<div class="caption">
										<h3>Guggenheim Museum</h3>
                    <p> NYC, 2018 </p>
									</div>
								</article>
								<article>
									<a href="images/ORG_DSC09076.JPG" class="image">
										<img src="images/ORG_DSC09076.JPG" alt="" />
									</a>
									<div class="caption">
										<h3>Monterey Aquarium</h3>
										<p>Monterey, 2018.</p>
									</div>
								</article>
								<article>
									<a href="images/ORG_DSC02377.JPG" class="image">
										<img src="images/ORG_DSC02377.JPG" alt="" />
									</a>
									<div class="caption">
										<h3>Izakaya</h3>
                    <p>Bay Area, 2019</p>
									</div>
								</article>
								</article>
								<article>
									<a href="images/ORG_DSC00939.JPG" class="image">
										<img src="images/ORG_DSC00939.JPG" alt="" />
									</a>
									<div class="caption">
										<h3>Dessert in Lauduree</h3>
										<p>NYC, 2018.</p>
									</div>
								</article>
								<article>
									<a href="images/ORG_DSC01179.JPG" class="image">
										<img src="images/ORG_DSC01179.JPG" alt="" />
									</a>
									<div class="caption">
										<h3>A Sushi Restaurant</h3>
                    <p>Carmel, 2019</p>
									</div>
								</article>
								<article>
									<a href="images/ORG_DSC01274.JPG" class="image">
										<img src="images/ORG_DSC01274.JPG" alt="" />
									</a>
									<div class="caption">
										<h3>An Italian Restaurant</h3>
                    <p>Bay Area, 2019</p>
									</div>
								</article>
								<article>
									<a href="images/ORG_DSC09185.JPG" class="image">
										<img src="images/ORG_DSC09185.JPG" alt="" />
									</a>
									<div class="caption">
										<h3>Duck Confit</h3>
                    <p>Monterey, 2018</p>
									</div>
								</article>
							</div>

					</section>


				<!-- Footer -->
					<footer class="wrapper style1 align-center">
						<div class="inner">
							<ul class="icons">
								<li><a href="https://github.com/Emma926" class="icon style2 fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="http://500px.com/emmawong926" class="icon style2 fa-500px"><span class="label">500PX</span></a></li>
								<li><a href="https://www.linkedin.com/in/emma-yu-wang-507b35bb/" class="icon style2 fa-linkedin"><span class="label">LinkedIn</span></a></li>
							</ul>
							<p>&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
